{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4227c16-e53d-4f1e-8ee0-bd064da2fdcd",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1d74a3-d9aa-4f38-a96d-a9dd8415275c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cbc2731-ce75-48e6-ba0c-7a559840c864",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely import Polygon\n",
    "from folium.raster_layers import ImageOverlay\n",
    "import io\n",
    "import base64\n",
    "import plotly.graph_objects as go\n",
    "import cmocean\n",
    "\n",
    "# from descartes import PolygonPatch\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.colors import Normalize, BoundaryNorm\n",
    "# from matplotlib.collections import PolyCollection  \n",
    "# from matplotlib.patches import Polygon\n",
    "import zarr\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "plt.style.use('seaborn-v0_8')\n",
    "\n",
    "\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "from matplotlib.patches import Polygon as MplPolygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.collections import PatchCollection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7de842-854e-4a61-9ab0-dfa4d2096977",
   "metadata": {},
   "source": [
    "# Simulation Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c34a8e94-c1b7-4c3f-86c8-e7273e27b95c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Load 4D ERA5 data as xarray.core.dataset.Dataset from $DATA\n",
    "\n",
    "Some important properties\n",
    "    Latitude \n",
    "        Range [44.23337936401367, 46.7599983215332] degrees North\n",
    "    Longitude\n",
    "        Range [-75.53164672851562, -71.8677978515625] degrees East\n",
    "    Rotated Pole\n",
    "        longitude, latitude [-73.57501220703125,45.5]\n",
    "    Time scales:\n",
    "        tas  - hourly\n",
    "        tmax - daily\n",
    "        q    - 3 hourly \n",
    "\"\"\"\n",
    "# without TEB\n",
    "tas_n = xr.open_zarr('/runoff/gulley/St_Laurent/StLaurent_1km_SL2.5_ERA5_advHU/tas.zarr')      \n",
    "tmax_n= xr.open_zarr('/runoff/gulley/St_Laurent/StLaurent_1km_SL2.5_ERA5_advHU/tasmax.zarr')\n",
    "qn = xr.open_zarr('/runoff/gulley/St_Laurent/StLaurent_1km_SL2.5_ERA5_advHU/huss.zarr')\n",
    "\n",
    "# with TEB\n",
    "tas_t = xr.open_zarr('/runoff/gulley/St_Laurent/StLaurent_1km_SL2.5_ERA5_advHU_TEB/tas.zarr')\n",
    "tmax_t= xr.open_zarr('/runoff/gulley/St_Laurent/StLaurent_1km_SL2.5_ERA5_advHU_TEB/tasmax.zarr')\n",
    "qt = xr.open_zarr('/runoff/gulley/St_Laurent/StLaurent_1km_SL2.5_ERA5_advHU_TEB/huss.zarr')\n",
    "\n",
    "# static fields\n",
    "static_fields = xr.open_mfdataset('/runoff/gulley/St_Laurent/StLaurent_1km_SL2.5_ERA5_advHU_step0.nc')\n",
    "urban_fraction_2d = static_fields['furban'].isel(lev=5)\n",
    "lons = static_fields.lon.values\n",
    "lats = static_fields.lat.values\n",
    "\n",
    "# To account for the issue in the simulation in 2022, a slice of each dataset is loaded\n",
    "tas_n = tas_n.sel(time=slice('2021'))     \n",
    "tmax_n= tmax_n.sel(time=slice('2021'))\n",
    "qn = qn.sel(time=slice('2021'))\n",
    "\n",
    "# # with TEB\n",
    "tas_t = tas_t.sel(time=slice('2021'))     \n",
    "tmax_t= tmax_t.sel(time=slice('2021'))\n",
    "qt = qt.sel(time=slice('2021'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0795945b-44f6-4e25-8855-65a1b2893dc0",
   "metadata": {},
   "source": [
    "# Station data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef6f9ab5-cab6-4825-8457-f1249e9b2cd9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Load ECCC_AHCCD_gen3_temperature data for stations in Canada\n",
    "pavics = xr.open_dataset(\"https://pavics.ouranos.ca/twitcher/ows/proxy/thredds/dodsC/datasets/station_obs/ECCC_AHCCD_gen3_temperature.ncml\")\n",
    "\n",
    "# Restrict the selection by masking for only stations within the domain\n",
    "station_is_in_domain = (\n",
    "    (pavics.lat>44.23337936401367)    & \n",
    "    (pavics.lat <46.7599983215332)    & \n",
    "    (pavics.lon > -75.53164672851562) & \n",
    "    (pavics.lon < -71.8677978515625)\n",
    ")\n",
    "\n",
    "# Set the stations into a pandas dataframe\n",
    "stations = pavics.sel(station=station_is_in_domain).set_coords(['lat', 'lon', 'station_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735cc915-19ea-49c0-892b-20b3c9fd59b7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Map projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18c8f532-3864-499a-acef-7dca9f03dcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map formatting properties for field projection\n",
    "# bbox = [[44.23337936401367, -75.53164672851562], [46.7599983215332, -71.8677978515625]]\n",
    "\n",
    "lat_min = min(lats.flatten())\n",
    "lat_max = max(lats.flatten())\n",
    "lon_min = min(lons.flatten())\n",
    "lon_max = max(lons.flatten())\n",
    "\n",
    "centre_lat = (lat_min + lat_max) / 2\n",
    "centre_lon = (lon_min + lon_max) / 2\n",
    "bounds = [[lat_min, lon_min], [lat_max, lon_max]]\n",
    "extent = [lon_min, lon_max, lat_min, lat_max]\n",
    "\n",
    "# To project station data onto the map\n",
    "gdf = pd.read_pickle('polygons_gdf.pkl')\n",
    "patches = [MplPolygon(np.array(poly.exterior.coords), closed=True) for poly in gdf.geometry]\n",
    "\n",
    "station_locations = stations[['lat', 'lon', 'station_name']].to_dataframe().reset_index()\n",
    "geojson_stations = gpd.GeoDataFrame(\n",
    "    station_locations, geometry=gpd.points_from_xy(station_locations['lon'], station_locations['lat'])\n",
    ").to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2ae52f2-02ec-46ab-94f8-bbddc22960d1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def show_colorbar(vmin=None,vmax=None,levels=20,cmap='bwr',orientation='horizontal'\n",
    "                  ,layout='constrained',label=None,adjustment = 0.,save_as=''):\n",
    "    # Creates a colour bar with discrete categories for map using matplotlib conventions\n",
    "    \n",
    "    fig,ax = plt.subplots(figsize=(7,1),layout=layout)\n",
    "    cmap = plt.get_cmap(cmap)\n",
    "    levels += 1\n",
    "    if vmin == None: vmin = 0\n",
    "    if vmax == None: vmax = 1\n",
    "    bounds = np.linspace(vmin,vmax,levels) -  adjustment\n",
    "    norm = BoundaryNorm(bounds, cmap.N)\n",
    "    fig.colorbar(ScalarMappable(norm=norm, cmap=cmap),\n",
    "                 cax=ax, orientation='horizontal', label=label)\n",
    "    if save_as!='':\n",
    "        plt.savefig(f'{save_as}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57cfef8c-915f-4d0f-94b8-8079d8612025",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def draw_map(field=None,cmap_name='bwr',vmin=None,vmax=None,num_levels=None,stations_visible=False,opacity=0.8,cmocean_CMAP=None):\n",
    "    \"\"\"\n",
    "    Creates a map and displays the station_locations within the bounds of the simulation on it. \n",
    "    It then generates an ImageOverlay of some the static field generated.\n",
    "    Example usage:\n",
    "        > f = tmax_n['tasmax'].sel(time='1999-03-08')\n",
    "        > m = draw_map(f)\n",
    "        > display(m)\n",
    "\n",
    "    parameters:\n",
    "        field - xarray.core.dataarray.DataArray\n",
    "            2D temperature, humidity, or other data \n",
    "        cmap - string\n",
    "            matplotlib colormap indicator\n",
    "        vmin, vmax - float \n",
    "            minimum and maximum \n",
    "    returns:\n",
    "        m - folium.folium.Map\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize the map\n",
    "    m = folium.Map(location=[centre_lat, centre_lon], zoom_start=8)\n",
    "\n",
    "    folium.TileLayer('cartodb positron').add_to(m)\n",
    "\n",
    "    if stations_visible:\n",
    "        # Add station markers\n",
    "        folium.GeoJson(\n",
    "            geojson_stations,\n",
    "            popup=folium.GeoJsonPopup(fields=['station_name'], aliases=['Station Name']),\n",
    "            marker=folium.CircleMarker(radius=3, color='grey', fill=True, fill_color='grey', fill_opacity=opacity)\n",
    "        ).add_to(m)\n",
    "\n",
    "    # Overlay field data\n",
    "    if field is not None:\n",
    "        # Create an image to store the field data\n",
    "        image_buffer = io.BytesIO()\n",
    "\n",
    "        # Field properties\n",
    "        norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "        \n",
    "        cmap = plt.get_cmap(cmap_name)\n",
    "        if cmocean_CMAP is not None:\n",
    "            cmap = cmocean_CMAP\n",
    "        sm = ScalarMappable(cmap=cmap, norm=norm)\n",
    "        \n",
    "        # Create the figure to save to the map\n",
    "        fig, ax = plt.subplots(figsize=(6, 6), dpi=800)\n",
    "        \n",
    "        bm = Basemap(projection='merc', \n",
    "            llcrnrlat=lat_min, \n",
    "            urcrnrlat=lat_max, \n",
    "            llcrnrlon=lon_min, \n",
    "            urcrnrlon=lon_max,ax=ax)\n",
    "\n",
    "        # This works fine, but it inserts resolution where none should exist!\n",
    "        # x, y = bm(lons, lats)\n",
    "        # bm.contourf(x, y, field.values, cmap=cmap_name,vmin= vmin,vmax= vmax, levels=num_levels,antialiased=False)\n",
    "        # XOR\n",
    "        # bm.pcolormesh(x, y, field.values, cmap=cmap_name,vmin= vmin,vmax= vmax)\n",
    "        \n",
    "        flat_field = np.ravel(field.values)\n",
    "        gdf['field'] = flat_field\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        collection = PatchCollection(\n",
    "            patches,\n",
    "            linewidth=0,\n",
    "            edgecolor='none',\n",
    "            antialiased=False\n",
    "        )\n",
    "        collection.set_array(gdf['field'].values)\n",
    "        collection.set_cmap(cmap)\n",
    "        collection.set_clim(vmin, vmax)\n",
    "        \n",
    "        \n",
    "        ax.add_collection(collection)\n",
    "        ax.autoscale_view()\n",
    "        ax.set_aspect('equal')\n",
    "        ax.axis('off')\n",
    "\n",
    "        minx, miny, maxx, maxy = gdf.total_bounds\n",
    "        ax.set_xlim(minx, maxx)\n",
    "        ax.set_ylim(miny, maxy)\n",
    "        \n",
    "        # Force the canvas to layout everything\n",
    "        # fig.canvas.draw()\n",
    "\n",
    "        # Then save\n",
    "        plt.savefig(image_buffer, format='png', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "\n",
    "\n",
    "        \n",
    "        ax.axis('off')  # Remove axes for clean image\n",
    "        \n",
    "        # Save image to buffer\n",
    "        plt.savefig(image_buffer, format='png', bbox_inches='tight', pad_inches=0, transparent=True)\n",
    "        plt.close(fig)\n",
    "        plt.close()\n",
    "        image_buffer.seek(0)\n",
    "        image_base64 = base64.b64encode(image_buffer.read()).decode()\n",
    "        image_uri = f\"data:image/png;base64,{image_base64}\"\n",
    "        # Read image from buffer and project onto map\n",
    "        ImageOverlay(\n",
    "            image=image_uri,\n",
    "            bounds=bounds,\n",
    "            opacity=0.6,\n",
    "            interactive=True,\n",
    "            cross_origin=False,\n",
    "            pixelated=True\n",
    "        ).add_to(m)\n",
    "        \n",
    "    m.fit_bounds(bounds)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3dab20-08f1-4cac-8928-a15f43d9b1c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Testing projection display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72198ca-548f-43a4-8153-519e566b7d1b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "f = tmax_n['tasmax'].sel(time='1999-03-31')\n",
    "m = draw_map(f,vmin=None,vmax=None)\n",
    "# m.save('/home/gulley/urban_heat_waves/tasmax_1999-03-31.html')\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54c6012-94c3-446a-8858-f9c2f0fc3583",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "f = urban_fraction_2d\n",
    "m = draw_map(f,vmin=-1,vmax=1,stations_visible=False)\n",
    "# m.save('/home/gulley/urban_heat_waves/tasmax_1999-03-31.html')\n",
    "display(m)\n",
    "show_colorbar(cmap='bwr',vmin=-1,vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c189f160-1aec-45aa-a84b-85472a6bc64e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Testing polygon generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ef376b-8efe-4550-a7e5-81f5f7469907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the polygon matrix\n",
    "# with open('polygons_updated.pkl', 'rb') as f:\n",
    "#     polygons_matrix = pickle.load(f)\n",
    "# polygons_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de5a07e-2e38-4aa4-9843-890e9e6e6ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the polygon matrix\n",
    "# with open('polygons_updated.pkl', 'rb') as f:\n",
    "#     polygons_matrix = pickle.load(f)\n",
    "# polygons_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4f8cfb-5aa0-461a-b18c-8cecc36facef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf.to_pickle(\"polygons_gdf.pkl\")\n",
    "# gdf = pd.read_pickle(\"polygons_gdf.pkl\")\n",
    "\n",
    "# gdf = gpd.GeoDataFrame(geometry=flat_polygons)\n",
    "\n",
    "# # Plot the polygons\n",
    "# gdf.plot(cmap='viridis', edgecolor='black')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9e97ec-1c8f-4b4b-9739-08cddea49e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# field = tmax_n['tasmax'].sel(time='1999-03-31')\n",
    "# flat_field = np.ravel(field.values)\n",
    "# gdf[\"field\"] = flat_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145f0f09-3984-4dd3-8104-ec48c508ae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coords = [np.array(poly.exterior.coords) for poly in gdf.geometry]\n",
    "\n",
    "# with open(\"polygon_coords.pkl\", \"wb\") as f:\n",
    "#     pickle.dump(coords, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa05cbe-f853-4c68-8c0c-ce25647f88df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Humidity considerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17c1ca67-b68d-42f0-8a37-6b4b0a4a11ba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Calculate the 2D summer maximum daily 2m relative humidity field in time \n",
    "    1. Extract the 2D temperature field corresponding for each 3 hour 2m absolute humidity record \n",
    "    2. Mask humidity values for only summer\n",
    "    3. Apply saturation vapour pressure formula from Huang (2018)\n",
    "\"\"\"\n",
    "\n",
    "# 3 hour summer 2m temperature record to have equivalent sampling record\n",
    "tas_3h_summer_n = tas_n.groupby('time.season')['JJA'].resample(time='3h').nearest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3970762a-ab3a-498b-a755-62f6d9d0e22f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def SVP(T):\n",
    "    \"\"\"\n",
    "    Calculates the saturation vapour pressure values according to Huang (2018)\n",
    "    \n",
    "    parameters\n",
    "        T : numpy.float32\n",
    "            Temperature [K]\n",
    "    returns\n",
    "        e_s : numpy.float32\n",
    "            Saturation vapour pressure for a given T in Pa\n",
    "    \"\"\"\n",
    "    t = T - 273.15\n",
    "    e_s = 0.\n",
    "    # if t <= 0: # SVP of ice\n",
    "        # e_s = np.exp(43.494 - 6545.8/(t + 278)) / np.square(t+868)\n",
    "    # else: # SVP of water\n",
    "    e_s = np.exp(34.494 - 4924.99/(t+ 237.1)) / np.power(t+105,1.57)\n",
    "    return e_s\n",
    "\n",
    "def VP(T,q):\n",
    "    \"\"\"\n",
    "    Approximates the actual vapour pressure using the ideal gas law\n",
    "\n",
    "    parameters\n",
    "        T : numpy.float32\n",
    "            Temperature [K]\n",
    "        q : numpy.float32\n",
    "            Specific humidity [kg/kg]\n",
    "    returns\n",
    "          : numpy.float32\n",
    "            Actual partial pressure of vapour in Pa\n",
    "    \"\"\"\n",
    "    M_v = 0.01802 #kg/mol molar mass of water\n",
    "    R = 8.314 #J/(mol K) ideal gas constant\n",
    "    rho_d = 1.293 #kg/m^2 density of dry air\n",
    "    e = 0.\n",
    "    q = np.abs(q)\n",
    "    \n",
    "    # if q!=0:\n",
    "    e = (q*rho_d*R*T) / ((1-q)*M_v)\n",
    "    return e\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fbe7cf0-32c6-4715-b6c3-0bce313c985d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def humidex(e,T):\n",
    "    \"\"\"\n",
    "    Index to indicate how hot or humid the weather feels to the average person according to ECCC technical documentation\n",
    "    \n",
    "    params\n",
    "        e : float\n",
    "            Vapour pressure [Pa]\n",
    "        T : float\n",
    "            Temperature [K]\n",
    "    returns\n",
    "        hdx : float \n",
    "            Humidex [C]\n",
    "    \"\"\"\n",
    "    return (T - 273.15) + (0.5555)*(e/100 - 10.0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7031e05f-e221-4339-a417-adc0fe639941",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Extracting summertime values and statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4880620c-95de-4a82-8eb3-eff4531a773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction of the tasmax_n, maximum daily t\n",
    "tmax_n_summer = tmax_n.groupby('time.season')['JJA']\n",
    "qn_summer = qn.groupby('time.season')['JJA']\n",
    "vps = VP(tas_3h_summer_n['tas'],qn_summer['huss'])\n",
    "svps = SVP(tas_3h_summer_n['tas'])\n",
    "RH_n_summer = vps/svps\n",
    "RH_max = RH_n_summer.resample(time='1D').max()\n",
    "RH_max_bar = RH_max.mean(dim='time')\n",
    "RH_bar = RH_n_summer.mean(dim='time')\n",
    "\n",
    "tasmax_bar = tmax_n_summer['tasmax'].mean(dim='time')\n",
    "tas_summer = tas_n['tas'].groupby('time.season')['JJA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29c1d666-5e60-4d75-afec-dbdb4935543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-hour humidex data according to ECCC technical documentation\n",
    "hdx = humidex(vps,tas_3h_summer_n['tas'])\n",
    "hdx_bar = hdx.mean(dim='time')\n",
    "hdx_max = hdx.resample(time='1D').max()\n",
    "hdx_max_bar = hdx_max.mean(dim='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84a80a5-5182-41d5-bf1d-76964606068a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Testing map functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6169186-6703-40b2-80db-6bde4a47d1ec",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# f = tasmax_bar\n",
    "# m = draw_map(f,stations_visible=False)\n",
    "# # m.save('/home/gulley/urban_heat_waves/tasmax_1999-03-31.html')\n",
    "# display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bb5867-8c50-4949-8685-4534decdacd1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# f = hdx_bar\n",
    "# m = draw_map(f,stations_visible=False)\n",
    "# # m.save('/home/gulley/urban_heat_waves/tasmax_1999-03-31.html')\n",
    "# display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de2a574-4b9d-40e7-9f71-12d8aa46b77d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# f = RH_max_bar\n",
    "# m = draw_map(f,stations_visible=False)\n",
    "# # m.save('/home/gulley/urban_heat_waves/tasmax_1999-03-31.html')\n",
    "# display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d45837-d9c6-4320-94f2-0401019675a9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# f = hdx_max_bar\n",
    "# m = draw_map(f,stations_visible=False)\n",
    "# # m.save('/home/gulley/urban_heat_waves/tasmax_1999-03-31.html')\n",
    "# display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e54d62d-a02e-4329-92ca-773db0c90d80",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Urban Fraction Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd599331-6349-4fa8-935f-0d4b901ed78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_urban = urban_fraction_2d>= 0.6\n",
    "is_suburban = (urban_fraction_2d<=0.3) & (urban_fraction_2d <0.6)\n",
    "is_rural = urban_fraction_2d < 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1689a97-c391-466d-a6e7-adf5397b4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plot the urban fraction\n",
    "\"\"\"\n",
    "f = urban_fraction_2d\n",
    "cmap = 'viridis'\n",
    "vmin = 0#min(np.ravel(f))\n",
    "vmax = 1#max(np.ravel(f))\n",
    "\n",
    "# show_colorbar(cmap=cmap,vmin=vmin,vmax=vmax,save_as='urban_fraction_colorbar.png',label='Urban Fraction')\n",
    "# m= draw_map(f,cmap_name = cmap)\n",
    "# display(m)\n",
    "# m.save('urban_fraction.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2d2915f2-d9d6-49e7-a515-25cf0a3ab8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time series binned by urban fraction for daily summer maximum temperature, humidity, humidex\n",
    "time_series = {'humidex':{'urban':None,'rural':None,'suburban':None},\n",
    "               'temperature':{'urban':None,'rural':None,'suburban':None},\n",
    "               'humidity':{'urban':None,'rural':None,'suburban':None}}\n",
    "\n",
    "for field in ['temperature','humidity','humidex']:\n",
    "    for urban_level in ['urban','suburban','rural']:\n",
    "        try: # Due to some sloppy naming conventions when saving dataarrays, I've put in this try statement\n",
    "            time_series[field][urban_level] = xr.open_zarr(f'time_series_{field}_{urban_level}.zarr')['__xarray_dataarray_variable__']\n",
    "        except: \n",
    "            time_series[field][urban_level] = xr.open_zarr(f'time_series_{field}_{urban_level}.zarr')['tas'] - 273.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8710a2aa-f2cc-4dfe-a685-dcffa1b27bbd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# General Diurnal Cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e964aff8-dd52-4fd1-a09b-2963ae95559e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "diurnal_cycles= {'humidex':{'urban':None,'rural':None,'suburban':None},\n",
    "                 'temperature':{'urban':None,'rural':None,'suburban':None},\n",
    "                 'humidity':{'urban':None,'rural':None,'suburban':None}}\n",
    "\n",
    "for field in ['temperature','humidity','humidex']:\n",
    "    for urban_level in ['urban','suburban','rural']:\n",
    "        diurnal_cycles[field][urban_level] = time_series[field][urban_level].groupby('time.hour').mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7ff3eec-42c9-4d0c-b874-1542d43e34f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure cycles are periodic\n",
    "# 3-hour seems to have excluded some things\n",
    "for field in ['humidity', 'humidex', 'temperature']:\n",
    "    for urban_level in ['urban', 'suburban', 'rural']:\n",
    "        da = diurnal_cycles[field][urban_level]\n",
    "        first_point = da.isel(hour=0).expand_dims(hour=[24])\n",
    "        diurnal_cycles[field][urban_level] = xr.concat([da, first_point], dim='hour')\n",
    "\n",
    "# Humidity graphs better as a percentage\n",
    "for urban_level in ['urban','suburban','rural']:\n",
    "    diurnal_cycles['humidity'][urban_level] = diurnal_cycles['humidity'][urban_level]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a1b03-a339-49b7-ad0e-90910f61c1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for field in ['temperature','humidity','humidex']:\n",
    "#     for urban_level in ['urban','suburban','rural']:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008c5a28-2cf1-42a0-80d8-335b225d91d7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "linestyle_map = {'temperature':'firebrick',\n",
    "                 'humidity':'royalblue',\n",
    "                 'humidex': 'magenta',\n",
    "                 'urban':3,\n",
    "                 'suburban':2,\n",
    "                 'rural':1}\n",
    "\n",
    "dash_map = {'urban':'solid',\n",
    "             'suburban':'dash',\n",
    "             'rural':'dot'}\n",
    "\n",
    "axis_map = {'temperature':'y1',\n",
    "            'humidity': 'y2',\n",
    "            'humidex': 'y1'}\n",
    "fig = go.Figure()\n",
    "\n",
    "for field in ['temperature','humidity','humidex']:\n",
    "    for urban_level in ['urban','rural']:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=diurnal_cycles[field][urban_level].coords['hour'],\n",
    "            y=diurnal_cycles[field][urban_level],\n",
    "            name=f'{urban_level.capitalize()} {field.capitalize()}',\n",
    "            yaxis=axis_map[field],\n",
    "            line=dict(color=linestyle_map[field], width=linestyle_map[urban_level],dash=dash_map[urban_level])\n",
    "))\n",
    "\n",
    "\n",
    "# Layout with two y-axes\n",
    "fig.update_layout(\n",
    "    title='Summer Diurnal Heat Cycles',\n",
    "    xaxis=dict(title='Time - UTZ ',\n",
    "              range=[0,24]),\n",
    "    yaxis=dict(\n",
    "        title='Temperature (C)'\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title='Humidity (%)',\n",
    "        overlaying='y',\n",
    "        side='right'\n",
    "    ),\n",
    "    \n",
    "    legend=dict(\n",
    "        orientation='h',    \n",
    "        yanchor='bottom',\n",
    "        y=-0.35, # Just below the plot             \n",
    "        xanchor='center',\n",
    "        x=0.5\n",
    "    ),\n",
    "    \n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "# fig.write_html('Summer_Diurnal_Heat_Cycle.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa7ce7f-e851-41dc-8ba2-ef85e74dfe83",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Time-averaged fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75fce60e-35f8-42c0-9efa-375ab30a67e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To calulate the summer month averages - these will be spatial fields (i.e. the averages in time.)\n",
    "    1. The base case includes all years over the time period\n",
    "    2. Only PNA- years to give PNA- anomalies\n",
    "    3. Only PNA+ years  to give PNA+ anomalies\n",
    "From this, we can subtract the values determined in cases 2 and 3 for the anomaly forcing of the PNA\n",
    "We must do this for each temperature, humidity, and heat stress\n",
    "\n",
    "Also consider a typical diurnal cycle for heat and the three-hour temperatures relating the PNA mask\n",
    "\"\"\"\n",
    "humidex_avg = xr.open_zarr('hdx_max_bar.zarr')['__xarray_dataarray_variable__']\n",
    "humidity_avg = xr.open_zarr('RH_max_bar.zarr')['__xarray_dataarray_variable__']\n",
    "tasmax_avg = xr.open_zarr('tasmax_bar')['tasmax']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aab173b-8744-4a92-8fd6-f7d5e9a148c6",
   "metadata": {},
   "source": [
    "## Typical maximum daily summer fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc00db2-93fb-4e1b-81f9-90c39ed98aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Average maximum daily summer humidity field\n",
    "\"\"\"\n",
    "f= humidity_avg\n",
    "cmap= 'Blues'\n",
    "\n",
    "vmax = np.round(max(np.ravel(f.values)),1)\n",
    "vmin = np.round(min(np.ravel(f.values)),1)\n",
    "\n",
    "m = draw_map(f, vmin= vmin, vmax = vmax, cmap_name = cmap)\n",
    "show_colorbar(vmin= vmin*100,vmax = vmax*100, cmap= cmap,save_as = 'typical_summer_maximum_humidity_cbar.png',label= 'Humidity (%)')\n",
    "# display(m)\n",
    "# m.save('typical_summer_maximum_humidity.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7ff00a-dc6b-4f9b-97a0-4862af239340",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Average maximum daily summer temperature field\n",
    "\"\"\"\n",
    "f = tasmax_avg\n",
    "vmax = 302.15#max(np.ravel(f.values))\n",
    "vmin = 292.15#min(np.ravel(f.values))\n",
    "\n",
    "m = draw_map(f, vmin= vmin, vmax = vmax, cmap_name = 'hot')\n",
    "show_colorbar(vmin= vmin,vmax = vmax, cmap= 'hot',adjustment=273.15,save_as = 'typical_summer_maximum_temperature_cbar.png',label= 'Temperature (C)')\n",
    "# display(m)\n",
    "# m.save('typical_summertime_maximum_temperature.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c909d9-7048-4199-9c98-d009d21041f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Average maximum daily summer humidex field\n",
    "    **This should be taken against the daily max summer temperature field with a grain of salt \n",
    "    (due to different sampling frequencies 3-hr vs 1-hr) \n",
    "    ** From the summer diurnal cycles however, it appears that humidity typically regulates temperature,\n",
    "    even in urban areas. Anomolously high humidity can change this  \n",
    "\"\"\"\n",
    "f = humidex_avg\n",
    "cmap = 'plasma'\n",
    "\n",
    "vmax = 29#max(np.ravel(f.values))\n",
    "vmin = 19#min(np.ravel(f.values))\n",
    "\n",
    "m = draw_map(f, vmin= vmin, vmax = vmax,cmap_name = cmap)\n",
    "show_colorbar(vmin= vmin,vmax = vmax, cmap= cmap,save_as = 'typical_summer_maximum_humidex_cbar.png',label= 'Humidex (C)')\n",
    "# display(m)\n",
    "# m.save('typical_summertime_maximum_humidex.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe39e18-8861-4054-ba87-898e32d4cf2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# PNA Spatial Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4802679d-e062-4280-a29b-6c4af7ab582e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now to load the PNA dataset for masking PNA+ and PNA- years\n",
    "pna = pd.read_csv('/runoff/gulley/scripts/dataFiles/NOAA_PNA_index_1999_2023.csv')\n",
    "pna.rename(columns={'Unnamed: 0': 'Year'}, inplace=True)\n",
    "pna.set_index('Year', inplace=True)\n",
    "summer_pna = pna[['Jun','Jul','Aug']].drop([2022,2023])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65411cdf-e1fa-49e2-9a00-8088a2ebfdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dataframe I just loaded so that it can be easier used with xarray, I could've just loaded xarray but here we are I guess\n",
    "pna_long = summer_pna.reset_index().melt(id_vars='Year', var_name='month', value_name='PNA')\n",
    "month_lookup = {'Jan':1, 'Feb':2, 'Mar':3, 'Apr':4, 'May':5, 'Jun':6,\n",
    "                'Jul':7, 'Aug':8, 'Sep':9, 'Oct':10, 'Nov':11, 'Dec':12}\n",
    "\n",
    "pna_long['month_num'] = pna_long['month'].map(month_lookup)\n",
    "pna_long['time'] = pd.to_datetime(dict(year=pna_long['Year'], month=pna_long['month_num'], day=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ff14196-d51d-4a5d-9a6c-6f0349c660aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_months = pna_long.loc[pna_long['PNA'] >= 0, 'time'].to_numpy(dtype='datetime64[ns]')\n",
    "negative_months = pna_long.loc[pna_long['PNA'] < 0, 'time'].to_numpy(dtype='datetime64[ns]')\n",
    "strongly_negative = pna_long.loc[pna_long['PNA'] >= 1, 'time'].to_numpy(dtype='datetime64[ns]')\n",
    "strongly_positive = pna_long.loc[pna_long['PNA'] <= -1, 'time'].to_numpy(dtype='datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfd0085f-11ea-4bdb-b44b-d932f9a68bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of dynamic anomaly fields\n",
    "tasmax_anomaly = tmax_n_summer - tasmax_avg\n",
    "humidex_anomaly = hdx_max - humidex_avg\n",
    "humidity_anomaly = RH_max - humidity_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b09692f8-b952-43da-89d0-cc0e2a187760",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Masking based on the strength of the PNA for summer months\n",
    "    - Includes all summer months where the PNA was within a particular range\n",
    "    - i.e. positive, negative, or strongly positive/negative if above 1 or below -1\n",
    "\"\"\"\n",
    "pna_fields = {'PNAP':{'temperature':None,'humidity':None,'humidex':None},\n",
    "             'PNAPP':{'temperature':None,'humidity':None,'humidex':None},\n",
    "             'PNAM':{'temperature':None,'humidity':None,'humidex':None},\n",
    "             'PNAMM':{'temperature':None,'humidity':None,'humidex':None}}\n",
    "\n",
    "for pna_state in ['PNAPP','PNAMM']: # This paper will only focus on the extremes\n",
    "    for field in ['temperature','humidity','humidex']:\n",
    "        try: # this gets stupider the more frequently I save it like this, whoops\n",
    "            pna_fields[pna_state][field] = xr.open_zarr(f'{field}_{pna_state}.zarr')['__xarray_dataarray_variable__']\n",
    "        except KeyError:\n",
    "            pna_fields[pna_state][field] = xr.open_zarr(f'{field}_{pna_state}.zarr')['tasmax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c1b12-1ace-4470-83ec-cb8be6e6d3f2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Plotting the anomaly fields based on the more extreme PNA months (+-1)\n",
    "\"\"\"\n",
    "units = {'temperature':'(C)',\n",
    "         'humidex':'(C)',\n",
    "         'humidity': '(%)'}\n",
    "\n",
    "cmaps = {'temperature':'hot',\n",
    "         'humidex':'plasma',\n",
    "         'humidity': 'Blues'}\n",
    "\n",
    "\n",
    "# f = pna_fields['PNAMM']['humidex'] - pna_fields['PNAPP']['humidex']\n",
    "\n",
    "for pna_state in ['PNAPP','PNAMM']: # This paper will only focus on the extremes\n",
    "    for field in ['humidity']:\n",
    "        cmap = cmaps[field]\n",
    "        f = pna_fields[pna_state][field]\n",
    "        vmax = max(np.ravel(f.values))\n",
    "        vmin = min(np.ravel(f.values))\n",
    "\n",
    "        \n",
    "        m = draw_map(f,vmin=vmin,vmax=vmax,cmap_name=cmap)#cmocean_CMAP=cmocean.cm.thermal)\n",
    "        if field == 'humidity':\n",
    "            vmin = vmin*100\n",
    "            vmax = vmax*100\n",
    "        show_colorbar(vmin= vmin,vmax = vmax, cmap= cmap,label= f'{field.capitalize()} Anomaly {units[field]}',save_as = f'anom_{field}_{pna_state}_cbar.png')\n",
    "        display(m)\n",
    "        # m.save(f'anom_{field}_{pna_state}.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b3e512-0725-42f5-823a-61615f25ad74",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Plotting the differences between PNA-- and PNA++ years\n",
    "\n",
    "vminmax = {'temperature' :[3.8, 2.5],\n",
    "           'humidity': [0.21,0.06],\n",
    "           'humidex': [4, 2]}\n",
    "\n",
    "\n",
    "for field in ['temperature','humidity','humidex']:\n",
    "    cmap = cmaps[field]\n",
    "    f = pna_fields['PNAMM'][field] - pna_fields['PNAPP'][field]\n",
    "    if field == 'humidity':\n",
    "        f = pna_fields['PNAPP'][field] - pna_fields['PNAMM'][field]\n",
    "    vmax = vminmax[field][0] #max(np.ravel(f.values))\n",
    "    vmin = vminmax[field][1] #min(np.ravel(f.values))\n",
    "    print(field)\n",
    "    print(vmax)\n",
    "    print(vmin)\n",
    "    print()\n",
    "    \n",
    "    m = draw_map(f,vmin=vmin,vmax=vmax,cmap_name=cmap)#cmocean_CMAP=cmocean.cm.thermal)\n",
    "    direction = 'PNAMM-PNAPP'\n",
    "    if field == 'humidity':\n",
    "        vmin = vmin*100\n",
    "        vmax = vmax*100\n",
    "        direction = 'PNAPP-PNAMM'\n",
    "    show_colorbar(vmin= vmin,vmax = vmax, cmap= cmap,label= f'{field.capitalize()} Difference {units[field]}',save_as = f'diff_{direction}_{field}_cbar.png')\n",
    "    # display(m)\n",
    "    # m.save(f'diff_{direction}_{field}.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8ae324-48d0-412b-9b63-3c9a1dec10a8",
   "metadata": {},
   "source": [
    "# PNA Diurnal Cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0331191e-11e6-4392-8d1d-8d213a2b42d5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "p_diurnal_series = {'humidex':{'urban':None,'rural':None,'suburban':None},\n",
    "               'temperature':{'urban':None,'rural':None,'suburban':None},\n",
    "               'humidity':{'urban':None,'rural':None,'suburban':None}}\n",
    "n_diurnal_series = {'humidex':{'urban':None,'rural':None,'suburban':None},\n",
    "               'temperature':{'urban':None,'rural':None,'suburban':None},\n",
    "               'humidity':{'urban':None,'rural':None,'suburban':None}}\n",
    "\n",
    "# Load the diurnal cycles\n",
    "for field in ['temperature', 'humidity','humidex']:\n",
    "    for urbanity in ['rural','urban']:\n",
    "        try: # Due to some sloppy naming conventions when saving dataarrays, I've put in this try statement\n",
    "            p_diurnal_series[field][urbanity] = xr.open_zarr(f'PNAPP_diurnal_{field}_{urbanity}.zarr')['__xarray_dataarray_variable__']\n",
    "            n_diurnal_series[field][urbanity] = xr.open_zarr(f'PNAMM_diurnal_{field}_{urbanity}.zarr')['__xarray_dataarray_variable__']\n",
    "        except KeyError: \n",
    "            p_diurnal_series[field][urbanity] = xr.open_zarr(f'PNAPP_diurnal_{field}_{urbanity}.zarr')['tas'] - 273.15\n",
    "            n_diurnal_series[field][urbanity] = xr.open_zarr(f'PNAMM_diurnal_{field}_{urbanity}.zarr')['tas'] - 273.15\n",
    "\n",
    "for field in ['humidity', 'humidex', 'temperature']:\n",
    "    for urbanity in ['urban', 'rural']:\n",
    "        p_da = p_diurnal_series[field][urbanity]\n",
    "        n_da = n_diurnal_series[field][urbanity]\n",
    "        \n",
    "        n_first_point = n_da.isel(hour=0).expand_dims(hour=[24])\n",
    "        p_first_point = p_da.isel(hour=0).expand_dims(hour=[24])\n",
    "        \n",
    "        p_diurnal_series[field][urbanity] = xr.concat([p_da, p_first_point], dim='hour')\n",
    "        n_diurnal_series[field][urbanity] = xr.concat([n_da, n_first_point], dim='hour')\n",
    "\n",
    "for urbanity in ['urban','rural']:\n",
    "    p_diurnal_series['humidity'][urbanity] = p_diurnal_series['humidity'][urbanity]*100\n",
    "    n_diurnal_series['humidity'][urbanity] = n_diurnal_series['humidity'][urbanity]*100\n",
    "\n",
    "diurnal_dict = {'All':diurnal_cycles,'PNA > +1.0': p_diurnal_series, 'PNA < -1.0':n_diurnal_series }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "14680b48-fa1e-4dd3-bc22-473acd0c9bb3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "linestyle_map = {'temperature':'firebrick',\n",
    "                 'humidity':'royalblue',\n",
    "                 'humidex': 'magenta',\n",
    "                 'urban':3,\n",
    "                 'suburban':2,\n",
    "                 'rural':1}\n",
    "\n",
    "dash_map = {'urban':'solid',\n",
    "             'suburban':'dash',\n",
    "             'rural':'dot'}\n",
    "\n",
    "axis_map = {'temperature':'y1',\n",
    "            'humidity': 'y2',\n",
    "            'humidex': 'y1'}\n",
    "\n",
    "PNA_flavour = {'All':'black',\n",
    "               'PNA > +1.0': 'red', \n",
    "               'PNA < -1.0':'blue' }\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for PNAnity in ['PNA > +1.0','All','PNA < -1.0']:\n",
    "    for field in ['humidex','temperature', 'humidity' ]:\n",
    "        for urban_level in ['urban','rural']:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=diurnal_dict[PNAnity][field][urban_level].coords['hour'],\n",
    "                y=diurnal_dict[PNAnity][field][urban_level],\n",
    "                name=f'{urban_level.capitalize()} {field.capitalize()} [{PNAnity}]',\n",
    "                yaxis=axis_map[field],\n",
    "                line=dict(color=linestyle_map[field], width=linestyle_map[urban_level],dash=dash_map[urban_level])\n",
    "    ))\n",
    "\n",
    "\n",
    "# Layout with two y-axes\n",
    "fig.update_layout(\n",
    "    title='Summer Diurnal Humidex Cycles - PNA Effects',\n",
    "    xaxis=dict(title='Time - UTZ ',\n",
    "              range=[0,24]),\n",
    "    yaxis=dict(\n",
    "        title='Temperature (C)'\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title='Humidity (%)',\n",
    "        overlaying='y',\n",
    "        side='right'\n",
    "    ),\n",
    "    \n",
    "    legend=dict(\n",
    "        orientation='h',    \n",
    "        yanchor='bottom',\n",
    "        y=-0.35, # Just below the plot             \n",
    "        xanchor='center',\n",
    "        x=0.5\n",
    "    ),\n",
    "    \n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "# fig.show()\n",
    "fig.write_html('all_diurnal_cycles.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e035866d-f1cb-409f-a008-8e441666ae5e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787dc02e-13fc-4b98-a7f4-ba128ad55280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Form for loading is straightforward\n",
    "# dataset = xr.open_zarr('path/to/variable.zarr')\n",
    "urban_masks = {'rural':is_rural, 'urban':is_urban}\n",
    "get_field = {'temperature':tas_summer, 'humidity':RH_n_summer, 'humidex':hdx}\n",
    "plus_slices = [slice(start, start + pd.offsets.MonthEnd(0)) for start in pd.to_datetime(strongly_positive)]\n",
    "minus_slices = [slice(start, start + pd.offsets.MonthEnd(0)) for start in pd.to_datetime(strongly_negative)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "163e776c-9cd0-424e-999b-f082292eb516",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "re-saving urban humidex after interruption\n",
      "humidex_urban done :)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nOriginal PNA masking, now saved, can be loaded by loop\\nThere was definitely a better way to do this - if it's stupid and it works, it isn't stupid\\n\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Some old code to ensure variables persist, lots of problems of course\n",
    "\n",
    "\"\"\"\n",
    "# hdx_max_bar.to_zarr('hdx_max_bar.zarr', mode='w')\n",
    "# hdx.to_zarr('hdx.zarr', mode='w')\n",
    "# hdx_bar.to_zarr('hdx_bar.zarr',mode='w')\n",
    "# hdx_max.to_zarr('hdx_max.zarr', mode='w')\n",
    "\n",
    "# RH_max_bar.to_zarr('RH_max_bar.zarr', mode='w')\n",
    "# # RH_max.to_zarr('RH_max.zarr', mode='w')\n",
    "# RH_bar.to_zarr('RH_bar.zarr',mode='w')\n",
    "# # RH.to_zarr('RH.zarr', mode='w')\n",
    "\n",
    "# tasmax_bar.to_zarr('tasmax_bar.zarr',mode='w')\n",
    "\n",
    "\n",
    "# # svps.to_zarr('svps.zarr',mode='w')\n",
    "# vps.to_zarr('vps.zarr',mode='w')\n",
    "# # tas_3h_summer_n.to_zarr('tas_3h.zarr',mode='w')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Original time_series loading, now saved, can be loaded by loop\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# time_series['humidex']['urban'] = hdx.where(is_urban).mean(dim=['rlat','rlon']).chunk(1450)\n",
    "# time_series['humidex']['suburban'] = hdx.where(is_suburban).mean(dim=['rlat','rlon']).chunk(1450)\n",
    "# time_series['humidex']['rural'] = hdx.where(is_rural).mean(dim=['rlat','rlon']).chunk(1450)\n",
    "\n",
    "# time_series['temperature']['urban'] = tas_summer.where(is_urban).mean(dim=['rlat','rlon']).chunk(1450)\n",
    "# time_series['temperature']['suburban'] = tas_summer.where(is_suburban).mean(dim=['rlat','rlon']).chunk(1450)\n",
    "# time_series['temperature']['rural'] = tas_summer.where(is_rural).mean(dim=['rlat','rlon']).chunk(1450)\n",
    "\n",
    "# time_series['humidity']['urban'] = RH_n_summer.where(is_urban).mean(dim=['rlat','rlon']).chunk(1450)\n",
    "# time_series['humidity']['suburban'] = RH_n_summer.where(is_suburban).mean(dim=['rlat','rlon']).chunk(1450)\n",
    "# time_series['humidity']['rural'] = RH_n_summer.where(is_rural).mean(dim=['rlat','rlon']).chunk(1450)\n",
    "# for field in ['temperature','humidity','humidex']:\n",
    "#     for urban_level in ['urban','suburban','rural']:\n",
    "#         time_series[field][urban_level].to_zarr(f'time_series_{field}_{urban_level}.zarr', mode='w')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Original masking for PNA-dependent diurnal cycles, now saved, can be loaded by loop\n",
    "\n",
    "\"\"\"\n",
    "# for field in ['temperature', 'humidity','humidex']:\n",
    "#     for urbanity in ['rural','urban']:\n",
    "#         conc = xr.concat([get_field[field].where(urban_masks[urbanity]).sel(time=slice(start, start + pd.offsets.MonthEnd(0))) for start in pd.to_datetime(strongly_positive)],dim='time')\n",
    "#         p_diurnal_series[field][urbanity] = conc.mean(dim= ['rlat','rlon']).groupby('time.hour').mean(dim='time') \n",
    "\n",
    "#         conc = xr.concat([get_field[field].where(urban_masks[urbanity]).sel(time=slice(start, start + pd.offsets.MonthEnd(0))) for start in pd.to_datetime(strongly_negative)],dim='time')\n",
    "#         n_diurnal_series[field][urbanity] = conc.mean(dim= ['rlat','rlon']).groupby('time.hour').mean(dim='time') \n",
    "\n",
    "# for field in ['temperature', 'humidity','humidex']:\n",
    "#     for urbanity in ['rural','urban']:\n",
    "#         p_diurnal_series[field][urbanity].to_zarr(f'PNAPP_diurnal_{field}_{urbanity}.zarr', mode='w')\n",
    "#         n_diurnal_series[field][urbanity].to_zarr(f'PNAMM_diurnal_{field}_{urbanity}.zarr', mode='w')\n",
    "#         print(f'{field}_{urbanity} done :)')\n",
    "\n",
    "\"\"\"\n",
    "Original PNA spatial masking, now saved, can be loaded by loop\n",
    "There was definitely a better way to do this - if it's stupid and it works, it isn't stupid\n",
    "\"\"\"\n",
    "\n",
    "# # # For temperature\n",
    "# T_PNAP = xr.concat(\n",
    "#     [tasmax_anomaly.sel(time=slice(start, start + pd.offsets.MonthEnd(0)))\n",
    "#      for start in pd.to_datetime(positive_months)],\n",
    "#     dim='time'\n",
    "# )\n",
    "\n",
    "# T_PNAPP = T_PNAP = xr.concat(\n",
    "#     [tasmax_anomaly.sel(time=slice(start, start + pd.offsets.MonthEnd(0)))\n",
    "#      for start in pd.to_datetime(strongly_positive)],\n",
    "#     dim='time'\n",
    "# )\n",
    "\n",
    "# T_PNAM = xr.concat(\n",
    "#     [tasmax_anomaly.sel(time=slice(start, start + pd.offsets.MonthEnd(0)))\n",
    "#      for start in pd.to_datetime(negative_months)],\n",
    "#     dim='time'\n",
    "# )\n",
    "\n",
    "# T_PNAMM = T_PNAP = xr.concat(\n",
    "#     [tasmax_anomaly.sel(time=slice(start, start + pd.offsets.MonthEnd(0)))\n",
    "#      for start in pd.to_datetime(strongly_negative)],\n",
    "#     dim='time'\n",
    "# )\n",
    "\n",
    "\n",
    "# # # For humidex\n",
    "# HDX_PNAP = xr.concat(\n",
    "#     [humidex_anomaly.sel(time=slice(start, start + pd.offsets.MonthEnd(0)))\n",
    "#      for start in pd.to_datetime(positive_months)],\n",
    "#     dim='time'\n",
    "# )\n",
    "\n",
    "# HDX_PNAPP = xr.concat(\n",
    "#     [humidex_anomaly.sel(time=slice(start, start + pd.offsets.MonthEnd(0)))\n",
    "#      for start in pd.to_datetime(strongly_positive)],\n",
    "#     dim='time'\n",
    "# )\n",
    "\n",
    "# HDX_PNAM = xr.concat(\n",
    "#     [humidex_anomaly.sel(time=slice(start, start + pd.offsets.MonthEnd(0)))\n",
    "#      for start in pd.to_datetime(negative_months)],\n",
    "#     dim='time'\n",
    "# )\n",
    "\n",
    "# HDX_PNAMM = xr.concat(\n",
    "#     [humidex_anomaly.sel(time=slice(start, start + pd.offsets.MonthEnd(0)))\n",
    "#      for start in pd.to_datetime(strongly_negative)],\n",
    "#     dim='time'\n",
    "# )\n",
    "\n",
    "\n",
    "# # # For humidity\n",
    "# H_PNAP = xr.concat(\n",
    "#     [humidity_anomaly.sel(time=slice(start, start + pd.offsets.MonthEnd(0)))\n",
    "#      for start in pd.to_datetime(positive_months)],\n",
    "#     dim='time'\n",
    "# )\n",
    "\n",
    "# H_PNAPP = xr.concat(\n",
    "#     [humidity_anomaly.sel(time=slice(start, start + pd.offsets.MonthEnd(0)))\n",
    "#      for start in pd.to_datetime(strongly_positive)],\n",
    "#     dim='time'\n",
    "# )\n",
    "\n",
    "\n",
    "# H_PNAM = xr.concat(\n",
    "#     [humidity_anomaly.sel(time=slice(start, start + pd.offsets.MonthEnd(0)))\n",
    "#      for start in pd.to_datetime(negative_months)],\n",
    "#     dim='time'\n",
    "# )\n",
    "\n",
    "# H_PNAMM = xr.concat(\n",
    "#     [humidity_anomaly.sel(time=slice(start, start + pd.offsets.MonthEnd(0)))\n",
    "#      for start in pd.to_datetime(strongly_negative)],\n",
    "#     dim='time'\n",
    "# )\n",
    "\n",
    "# HDX_PNAPP_bar = HDX_PNAPP.mean(dim='time')\n",
    "# HDX_PNAMM_bar = HDX_PNAMM.mean(dim='time')\n",
    "\n",
    "# T_PNAPP_bar = T_PNAPP.mean(dim='time')\n",
    "# T_PNAMM_bar = T_PNAMM.mean(dim='time')\n",
    "\n",
    "# H_PNAPP_bar = H_PNAPP.mean(dim='time')\n",
    "# H_PNAMM_bar = H_PNAMM.mean(dim='time')\n",
    "\n",
    "\n",
    "# # For humidex\n",
    "# HDX_PNAPP_bar.to_zarr('humidex_PNAPP.zarr', mode='w')\n",
    "# print('done')\n",
    "# HDX_PNAMM_bar.to_zarr('humidex_PNAMM.zarr', mode='w')\n",
    "# print('done')\n",
    "\n",
    "# # For humidity\n",
    "# H_PNAPP_bar.to_zarr('humidity_PNAPP.zarr', mode='w')\n",
    "# print('done')\n",
    "# H_PNAMM_bar.to_zarr('humidity_PNAMM.zarr', mode='w')\n",
    "# print('done')\n",
    "\n",
    "# T_PNAPP_bar.to_zarr('temperature_PNAPP.zarr', mode='w')\n",
    "# print('done')\n",
    "# T_PNAMM_bar.to_zarr('temperature_PNAMM.zarr', mode='w')\n",
    "# print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
